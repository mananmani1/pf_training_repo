{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import Dependencies**"
      ],
      "metadata": {
        "id": "rSHcMQyttI7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxk2qKzbeEev",
        "outputId": "20dee481-f972-447b-f9a1-cf7996ac2ecc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emnist in /usr/local/lib/python3.9/dist-packages (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from emnist) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from emnist) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from emnist) (1.22.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->emnist) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->emnist) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->emnist) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->emnist) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from emnist import list_datasets\n",
        "from emnist import extract_training_samples, extract_test_samples\n",
        "\n"
      ],
      "metadata": {
        "id": "Ew2jKioebEBz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Emnist Digit Dataset**"
      ],
      "metadata": {
        "id": "_QkuEaUfDpn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3BGd1Dy1w0x",
        "outputId": "eccea0f0-0f09-46f5-dd32-d525dd8bb3af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = extract_training_samples('digits')\n",
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czAFAJoW1RL2",
        "outputId": "a29b09da-ec2f-4376-bab0-68d0fb7ab8d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading and Preprocessing**"
      ],
      "metadata": {
        "id": "gADAFoWyfoet"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DeaQEmKCY6vN"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset of emnist dataset\n",
        "def load_dataset():\n",
        " trainX, trainY = extract_training_samples('digits')\n",
        " testX, testY = extract_test_samples('digits')\n",
        " # reshape dataset to have a single channel as for grayscale image\n",
        " trainX = trainX.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        " testX = testX.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "  #  target values\n",
        " trainY = to_categorical(trainY)\n",
        " testY = to_categorical(testY)\n",
        " return trainX, trainY, testX, testY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load pre trained model**"
      ],
      "metadata": {
        "id": "CT5UVWA6f1O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = load_model('my_trained_model.h5')\n"
      ],
      "metadata": {
        "id": "-ARqr7OvOEHb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add layers to trained model\n",
        "x = Flatten()(trained_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "lWZLh4ofN_We"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the transfer learning model\n",
        "transfer_model = Model(inputs=trained_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "JbTd1OHDOezm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze pre-trained model layer\n",
        "for layer in trained_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "5oWN3lanOwZ6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "transfer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-qiSSfAaO-mQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training and Evaluation**"
      ],
      "metadata": {
        "id": "YVjZ_zEndT_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy():\n",
        "  trainX, trainY, testX, testY = load_dataset()\n",
        "  transfer_model.fit(trainX, trainY, batch_size=64, epochs=5, validation_data=(testX, testY))\n",
        "  loss, acc = transfer_model.evaluate(testX, testY, verbose=1)\n",
        "\n",
        "  #Check Loss and Accuracy\n",
        "  print('Test Loss: %.3f' % loss)\n",
        "  print('Test Accuracy: %.3f' % (acc * 100.0))\n",
        "\n",
        " \n",
        "check_accuracy()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8-uONLgrT90",
        "outputId": "f7853f0b-d5de-48dc-85e6-522d426ab0e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3750/3750 [==============================] - 121s 32ms/step - loss: 0.2185 - accuracy: 0.9506 - val_loss: 0.1700 - val_accuracy: 0.9575\n",
            "Epoch 2/5\n",
            "3750/3750 [==============================] - 126s 34ms/step - loss: 0.1635 - accuracy: 0.9596 - val_loss: 0.1552 - val_accuracy: 0.9624\n",
            "Epoch 3/5\n",
            "3750/3750 [==============================] - 114s 30ms/step - loss: 0.1496 - accuracy: 0.9627 - val_loss: 0.1420 - val_accuracy: 0.9643\n",
            "Epoch 4/5\n",
            "3750/3750 [==============================] - 114s 30ms/step - loss: 0.1396 - accuracy: 0.9646 - val_loss: 0.1373 - val_accuracy: 0.9652\n",
            "Epoch 5/5\n",
            "3750/3750 [==============================] - 120s 32ms/step - loss: 0.1323 - accuracy: 0.9657 - val_loss: 0.1281 - val_accuracy: 0.9664\n",
            "1250/1250 [==============================] - 19s 15ms/step - loss: 0.1281 - accuracy: 0.9664\n",
            "Test Loss: 0.128\n",
            "Test Accuracy: 96.635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input Image**"
      ],
      "metadata": {
        "id": "MGQcgVv9uvvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(filename):\n",
        " img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        " # convert to array\n",
        " img = img_to_array(img)\n",
        " # reshape into a single sample with 1 channel as for grayscale image\n",
        " img = img.reshape(1, 28, 28, 1)\n",
        " # prepare pixel data\n",
        " img = img.astype('float32')\n",
        " img = img / 255.0\n",
        " return img"
      ],
      "metadata": {
        "id": "WdYg6SZMeCR7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the emnist image for test purpose as I have downloaded in my machine\n",
        "image = Image.open('emnist_8.png')\n",
        "image.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "JEzSDPFbeCVd",
        "outputId": "02be6101-26d3-4dc2-b0bf-766139535cea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=389x389 at 0x7F7DE82F4760>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAALFUlEQVR4nO3cvWveZd/H8eNMYlOIVtC2iB1SC6WDpv0PCi4qVNogKmpnKSJIJW6iS0UQ8QFctA4OxQdctJjBQRcXXS2YIQiNQ1XSqihVG0xyXtP14b5vhCvf475yNrav15wPvx/Nw/s8hh6D4XA4bADQWhu72i8AwNYhCgCEKAAQogBAiAIAIQoAhCgAEKIAQExs9AsHg8FmvgcAm2wj/1fZSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgNnwhHvDPMzY2ms996+vrI3kOm89JAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBciAcjNjk52bU7cOBAefPss8+WN4PBoLw5c+ZMeTM/P1/etNbacDjs2rExTgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAxGC4wSsHe25OhGvdzp07y5vXXnut61mzs7PlzdTUVNezqn7//ffyZmZmputZS0tLXTs2dsOskwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBATFztF4CtYnx8vLw5ceJEefPggw+WN621Njk5Wd6M6iLLnnfr2bD5nBQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAYjAcDocb+sIRXawF/1fPz97BgwfLm5MnT5Y3jzzySHnTexHcVv4d3OCfkf/l3Xff7XrWc889V94sLS11Petas5Hvk5MCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQExc7ReA/6Tn0rnTp0+XN1NTU+XNKPVcOtfjypUr5c0ff/xR3jz88MPlTWutLS4uljenTp3qetb1yEkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIFyIx8hMTPT9uD399NPlzVa/3K5Hz0V1CwsL5c38/Hx5c8cdd5Q3jz76aHnTWmtjYz7Lbib/ugCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEW1IZmVtuuaVrNz09Xd4MBoPyZjgcljc//fRTedNzC2lrrb3++uvlzTfffFPebNu2rbw5d+5cecPW5KQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEC7Eo8vERP1H5/jx413P2rVrV3nTc7ndpUuXypvHH3+8vPnkk0/Km9ZaW19fL28mJyfLm4ceeqi86bm0sOd7xOZzUgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIF+IxMjt27BjZs9bW1sqb999/v7z59NNPy5uei+167dmzp7x58skny5vx8fHy5q+//ipvWhvtv9/1yEkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIFyIx8j89ttvI3vWcDgsb37++efyZmVlpbzptXfv3vLm1VdfLW9mZmbKmx4ffvhh1+7MmTP/5Tfhf3JSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACDckkqX1dXV8ubs2bNdz3rhhRfKmxtuuKG82bFjR3kzNlb/XLVv377yprXWXn755fLm6NGjXc+q+vbbb8ububm5rmctLy937dgYJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAcCEeI/P999937RYXF8ubQ4cOlTezs7Plzfz8fHnz1FNPlTettXbvvfd27arW19fLmxdffLG8uXjxYnnD5nNSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIjBcDgcbugLB4PNfhf4Wz2X23355Zflzfbt28ubtbW18mZ8fLy8GaXl5eXyZmZmprxxId7obeTPvZMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQExc7ReA/2RxcbG8+fHHH8ubvXv3ljcTE/VfoQ3eQflfsbS0VN589tln5c0vv/xS3rA1OSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhAvxGJnBYNC1O3DgQHlz4403dj1rK7t06VJ5c88995Q358+fL2/W1tbKG7YmJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwi2ptMnJyfLmzjvvLG+OHj1a3rTW2tzcXHkzNTVV3qyurpY3PTe/jo+PlzettXb58uXy5sKFC+WNG0+vb04KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFCvGvMxET9W3rfffeVN6+88kp5c/vtt5c3rbW2ffv28ub8+fPlzccff1zebNu2rbx54oknypvWWrvtttvKm/3795c3586dK2+4djgpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQL8bao3bt3d+1eeuml8ubIkSPlzc6dO8ubXpcvXy5vHnjggfKm5yK4kydPljdjY32fxXouBjx27Fh5s7CwUN6srq6WN2xNTgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4UK8op7LzO6+++7y5q233ipvWmtt3759Xbuq5eXl8ubtt9/uetY777xT3iwtLZU309PT5c39999f3oxSz2WCXN+cFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDChXhFt956a3lz4sSJ8mZUF9u11tqVK1fKmzfeeKO86b0Q7+LFi+XNwYMHy5tnnnmmvDl8+HB506vn+/T555+XN6urq+UN1w4nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCLalFN998c3lz6NChTXiTv/fdd9+VN88//3x5895775U3Y2N9n0Eee+yx8ubNN98sb6ampsqbHisrK127r776qrxZWFjoehbXLycFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgHAhXtGvv/5a3nz99dflzf79+8ub1lq76aabypvZ2dny5tixY+XNXXfdVd601tr09HR5Mzk52fWsquXl5fJmbm6u61kfffRRebO6utr1LK5fTgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMRgOh8MNfeFgsNnv8o8wPj5e3hw5cqS8OX36dHnTWmu7du0qbzb4I/D/NjY2us8gf/75Z3nzww8/lDenTp0qbz744IPyprXWVlZWunbwbxv5XXdSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgX4m1Ru3fv7todP368vNmzZ095c/jw4fLmiy++KG9aa+3ChQvlzdmzZ8ubngvxei7eg6vFhXgAlIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLgllS7j4+Plzdra2ia8CbBRbkkFoEQUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgJi42i/AP5PL7eDa5KQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEBu+EG84HG7mewCwBTgpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEP8CQV2fPeB93wMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**"
      ],
      "metadata": {
        "id": "XjlzNqfDufPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load an image and predict the label of image\n",
        "def run_example():\n",
        " img = load_image('emnist_8.png')\n",
        "#  load model\n",
        " predict_value = transfer_model.predict(img)\n",
        " digit = argmax(predict_value)\n",
        " print(digit)\n",
        " \n",
        "run_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Myde0e9baBM",
        "outputId": "91974b7b-e539-473b-9d14-7e0d6d0f5483"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 154ms/step\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hence our pretrained model's weights over mnist digit dataset perform transfer learning very well over new emnist digit*"
      ],
      "metadata": {
        "id": "ULWUZHvSFPHi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4Gc5YuuF3_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}